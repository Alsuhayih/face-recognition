{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import face_recognition as fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 410 101 101\n",
      "409 359 101 101\n",
      "427 361 101 101\n",
      "428 375 101 101\n",
      "427 360 101 101\n",
      "423 362 101 101\n",
      "418 364 101 101\n",
      "422 361 101 101\n",
      "432 360 101 101\n",
      "484 391 101 101\n",
      "494 394 101 101\n",
      "492 400 101 101\n",
      "485 400 101 101\n",
      "482 400 101 101\n",
      "483 400 101 101\n",
      "483 399 101 101\n",
      "483 396 101 101\n",
      "482 405 101 101\n",
      "483 401 101 101\n",
      "485 405 101 101\n",
      "487 406 101 101\n",
      "484 404 101 101\n",
      "482 399 101 101\n",
      "484 400 101 101\n",
      "484 404 101 101\n",
      "485 407 101 101\n",
      "488 409 101 101\n",
      "487 410 101 101\n",
      "488 407 101 101\n",
      "485 406 101 101\n",
      "485 403 101 101\n",
      "486 401 101 101\n",
      "484 400 101 101\n",
      "485 402 101 101\n",
      "485 400 101 101\n",
      "478 394 101 101\n",
      "480 396 101 101\n",
      "483 398 101 101\n",
      "479 394 101 101\n",
      "478 396 101 101\n",
      "478 394 101 101\n",
      "483 392 101 101\n",
      "482 399 101 101\n",
      "482 414 101 101\n",
      "461 418 101 101\n",
      "453 418 101 101\n",
      "932 290 342 342\n",
      "445 416 101 101\n",
      "451 419 101 101\n",
      "932 290 342 342\n",
      "458 421 101 101\n",
      "932 290 342 342\n",
      "933 278 342 342\n",
      "455 419 101 101\n",
      "455 430 101 101\n",
      "457 430 101 101\n",
      "932 273 342 342\n",
      "509 395 101 101\n",
      "515 391 101 101\n",
      "932 273 342 342\n",
      "508 395 101 101\n",
      "932 273 342 342\n",
      "509 395 101 101\n",
      "513 398 101 101\n",
      "932 273 342 342\n",
      "520 400 101 101\n",
      "934 282 342 342\n",
      "926 293 342 342\n",
      "520 416 101 101\n",
      "925 288 342 342\n",
      "925 279 342 342\n",
      "927 282 342 342\n",
      "923 290 342 342\n",
      "932 276 342 342\n",
      "534 405 101 101\n",
      "932 273 342 342\n",
      "501 421 101 101\n",
      "498 422 101 101\n",
      "932 273 342 342\n",
      "499 424 101 101\n",
      "501 424 101 101\n",
      "503 424 101 101\n",
      "932 273 342 342\n",
      "932 273 342 342\n",
      "509 424 101 101\n",
      "932 273 342 342\n",
      "932 273 342 342\n",
      "513 430 101 101\n",
      "933 278 342 342\n",
      "515 429 101 101\n",
      "934 282 342 342\n",
      "517 431 101 101\n",
      "925 288 342 342\n",
      "923 273 342 342\n",
      "921 275 342 342\n",
      "918 273 342 342\n",
      "925 275 342 342\n",
      "925 271 342 342\n",
      "925 269 342 342\n",
      "921 270 342 342\n",
      "914 267 342 342\n",
      "490 358 101 101\n",
      "908 271 342 342\n",
      "477 361 101 101\n",
      "902 273 342 342\n",
      "455 363 101 101\n",
      "906 273 342 342\n",
      "428 365 101 101\n",
      "402 346 152 152\n",
      "900 275 342 342\n",
      "421 371 101 101\n",
      "400 352 152 152\n",
      "899 273 342 342\n",
      "426 374 101 101\n",
      "400 354 152 152\n",
      "894 275 342 342\n",
      "426 376 101 101\n",
      "405 360 152 152\n",
      "899 276 342 342\n",
      "425 382 101 101\n",
      "402 362 152 152\n",
      "899 277 342 342\n",
      "416 386 101 101\n",
      "898 285 342 342\n",
      "417 388 101 101\n",
      "395 370 152 152\n",
      "902 279 342 342\n",
      "418 386 101 101\n",
      "395 370 152 152\n",
      "899 283 342 342\n",
      "416 389 101 101\n",
      "897 282 342 342\n",
      "412 388 101 101\n",
      "389 369 152 152\n",
      "896 279 342 342\n",
      "388 371 152 152\n",
      "895 280 342 342\n",
      "388 372 152 152\n",
      "897 276 342 342\n",
      "415 392 101 101\n",
      "899 273 342 342\n",
      "390 373 152 152\n",
      "900 271 342 342\n",
      "413 392 101 101\n",
      "904 271 342 342\n",
      "415 392 101 101\n",
      "902 275 342 342\n",
      "416 394 101 101\n",
      "902 273 342 342\n",
      "415 398 101 101\n",
      "395 376 152 152\n",
      "899 276 342 342\n",
      "395 378 152 152\n",
      "906 275 342 342\n",
      "420 396 101 101\n",
      "395 378 152 152\n",
      "906 273 342 342\n",
      "419 398 101 101\n",
      "395 378 152 152\n",
      "900 273 342 342\n",
      "397 379 152 152\n",
      "906 273 342 342\n",
      "394 381 152 152\n",
      "899 275 342 342\n",
      "421 399 101 101\n",
      "906 273 342 342\n",
      "421 404 101 101\n",
      "904 275 342 342\n",
      "425 405 101 101\n",
      "901 284 342 342\n",
      "426 406 101 101\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    #to capture frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.5,\n",
    "        minNeighbors=5\n",
    "        )\n",
    "    for (x, y, w, h) in faces:\n",
    "        print(x, y, w, h)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        #id_, conf = \n",
    "        #recognizer deep learning model\n",
    "        \n",
    "        img_item = \"img.png\"\n",
    "        cv2.imwrite(img_item, roi_gray)\n",
    "        \n",
    "        color = (255, 255, 255)\n",
    "        thinkness = 2\n",
    "        width = x + w\n",
    "        height = y + h\n",
    "        cv2.rectangle(frame, (x, y), (width, height), color, thinkness)\n",
    "        \n",
    "    #to display the results of the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images\n"
     ]
    }
   ],
   "source": [
    "image_dir = os.path.join('images')\n",
    "print(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill images/bill/8.jpg\n",
      "bill images/bill/9.jpg\n",
      "bill images/bill/12.jpg\n",
      "bill images/bill/11.jpg\n",
      "bill images/bill/10.jpg\n",
      "bill images/bill/5.png\n",
      "bill images/bill/7.jpg\n",
      "bill images/bill/6.jpg\n",
      "bill images/bill/2.jpg\n",
      "bill images/bill/3.jpg\n",
      "bill images/bill/1.jpg\n",
      "ibrahim images/ibrahim/8.jpg\n",
      "ibrahim images/ibrahim/9.jpg\n",
      "ibrahim images/ibrahim/test1.jpg\n",
      "ibrahim images/ibrahim/test2.jpg\n",
      "ibrahim images/ibrahim/test.jpg\n",
      "ibrahim images/ibrahim/4.jpg\n",
      "ibrahim images/ibrahim/5.jpg\n",
      "ibrahim images/ibrahim/7.jpg\n",
      "ibrahim images/ibrahim/6.jpg\n",
      "ibrahim images/ibrahim/2.jpg\n",
      "ibrahim images/ibrahim/3.jpg\n",
      "ibrahim images/ibrahim/1.jpg\n",
      "jassim images/jassim/8.jpg\n",
      "jassim images/jassim/9.jpg\n",
      "jassim images/jassim/14.jpg\n",
      "jassim images/jassim/15.jpg\n",
      "jassim images/jassim/16.jpg\n",
      "jassim images/jassim/12.jpg\n",
      "jassim images/jassim/13.jpg\n",
      "jassim images/jassim/11.jpg\n",
      "jassim images/jassim/10.jpg\n",
      "jassim images/jassim/4.jpg\n",
      "jassim images/jassim/5.jpg\n",
      "jassim images/jassim/7.jpg\n",
      "jassim images/jassim/6.jpg\n",
      "jassim images/jassim/2.jpg\n",
      "jassim images/jassim/1.jpg\n",
      "obama images/obama/8.jpg\n",
      "obama images/obama/9.jpg\n",
      "obama images/obama/j3.jpg\n",
      "obama images/obama/11.jpg\n",
      "obama images/obama/10.jpg\n",
      "obama images/obama/4.jpg\n",
      "obama images/obama/5.jpg\n",
      "obama images/obama/7.jpg\n",
      "obama images/obama/6.jpg\n",
      "obama images/obama/2.jpg\n",
      "obama images/obama/1.jpg\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('png') or file.endswith('jpg'):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(os.path.dirname(path)).replace(\" \", '-').lower()\n",
    "            print(label, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[176 174 169 ... 174 174 174]\n",
      " [176 174 169 ... 174 174 174]\n",
      " [176 175 170 ... 174 174 174]\n",
      " ...\n",
      " [ 53  53  53 ...  14  13  12]\n",
      " [ 53  53  53 ...  13  13  12]\n",
      " [ 53  53  53 ...  13  12  12]]\n"
     ]
    }
   ],
   "source": [
    "pil_image = Image.open(path).convert(\"L\") #grayscale\n",
    "image_array = np.array(pil_image, 'uint8')\n",
    "print(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obama': 0}\n"
     ]
    }
   ],
   "source": [
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []\n",
    "\n",
    "if not label in label_ids:\n",
    "    label_ids[label] = current_id\n",
    "    current_id += 1\n",
    "    id_ = label_ids[label]\n",
    "#id_ = label_ids[label]\n",
    "print(label_ids)\n",
    "#y_labels.append(label)\n",
    "#x_train.append(path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt2.xml')\n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "y_labels = []\n",
    "x_train = []\n",
    "\n",
    "for root, dirs, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('png') or file.endswith('jpg'):\n",
    "            path = os.path.join(root, file)\n",
    "            label = os.path.basename(os.path.dirname(path)).replace(\" \", '-').lower()\n",
    "            #print(label, path)\n",
    "            \n",
    "            \n",
    "            if not label in label_ids:\n",
    "                label_ids[label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[label]\n",
    "            #print(label_ids)\n",
    "            #y_labels.append(label)\n",
    "            #x_train.append(path)\n",
    "            \n",
    "            \n",
    "            pil_image = Image.open(path).convert(\"L\") #grayscale\n",
    "            size = (550,550)\n",
    "            final_image = pil_image.resize(size, Image.ANTIALIAS)\n",
    "            image_array = np.array(pil_image, 'uint8')\n",
    "            #print(image_array)\n",
    "            \n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                image_array,\n",
    "                scaleFactor=1.5,\n",
    "                minNeighbors=5\n",
    "            )\n",
    "            for (x,y,w,h) in faces:\n",
    "                roi = image_array[y:y+h, x:x+w]\n",
    "                x_train.append(roi)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "#print(y_labels)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"labels.pickle\", \"wb\") as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "face_recognizer.train(x_train, np.array(y_labels))\n",
    "face_recognizer.save(\"trainner.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer.read(\"trainner.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453 192 513 513\n",
      "3\n",
      "obama\n"
     ]
    }
   ],
   "source": [
    "labels1 = {}\n",
    "#with open(\"labels.pickle\", \"rb\") as f:\n",
    "   # labels1 = pickle.load(label_ids, f)\n",
    "with open(\"labels.pickle\", \"rb\") as f:\n",
    "    og_labels = pickle.load(f)\n",
    "    labels1 = {v:k for k,v in og_labels.items()}\n",
    "\n",
    "\n",
    "    \n",
    "for (x, y, w, h) in faces:\n",
    "    \n",
    "    print(x, y, w, h)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = frame[y:y+h, x:x+w]\n",
    "               \n",
    "            \n",
    "            #recognizer deep learning model this\n",
    "    id_, conf = face_recognizer.predict(roi_gray)\n",
    "    if conf>=40:\n",
    "        #and conf<=80\n",
    "        print(id_)\n",
    "        print(labels1[id_])\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        name = labels1[id_]\n",
    "        color = (255,255,255)\n",
    "        stroke = 2\n",
    "        cv2.putText(frame, name, (x,y), font, 1, color, stroke, cv2.LINE_AA)\n",
    "        \n",
    "        img_item = \"images/jassim/11.jpg\"\n",
    "        cv2.imwrite(img_item, roi_gray)\n",
    "        \n",
    "        color = (255, 255, 255)\n",
    "        thinkness = 2\n",
    "        width = x + w\n",
    "        height = y + h\n",
    "        #cv2.rectangle(frame, (x, y), (width, height), color, thinkness)\n",
    "        \n",
    "    #to display the results of the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
